{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `/opt/julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %]  41.1 %==================================>      ]  82.5 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====================================>   ]  90.4 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m MutableArithmetics ─ v0.2.8\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m JuMP ─────────────── v0.21.2\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.3/Project.toml`\n",
      " \u001b[90m [4076af6c]\u001b[39m\u001b[93m ↑ JuMP v0.21.1 ⇒ v0.21.2\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.3/Manifest.toml`\n",
      " \u001b[90m [4076af6c]\u001b[39m\u001b[93m ↑ JuMP v0.21.1 ⇒ v0.21.2\u001b[39m\n",
      " \u001b[90m [d8a4904e]\u001b[39m\u001b[93m ↑ MutableArithmetics v0.2.7 ⇒ v0.2.8\u001b[39m\n",
      " \u001b[90m [ea10d353]\u001b[39m\u001b[95m ↓ WeakRefStrings v0.6.2 ⇒ v0.5.8\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.3/Project.toml`\n",
      " \u001b[90m [bd369af6]\u001b[39m\u001b[92m + Tables v1.0.3\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.3/Manifest.toml`\n",
      " \u001b[90m [ea10d353]\u001b[39m\u001b[93m ↑ WeakRefStrings v0.5.8 ⇒ v0.6.2\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "pkg\"up\"\n",
    "pkg\"add BenchmarkTools PyCall CSV DataFrames LibPQ IterTools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    ";conda install numpy pandas sqlalchemy psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using CSV\n",
    "using DataFrames\n",
    "using PyCall\n",
    "using Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'numpy' from '/opt/conda/lib/python3.7/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd = pyimport(\"pandas\")\n",
    "np = pyimport(\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"https://nyc-tlc.s3.amazonaws.com/trip+data/green_tripdata_2019-12.csv\", \n",
    "    \"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.241610527038574"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesize(\"test_data.csv\")/1024^2 # in MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate PyCall Overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is the potential influence of PyCall to the Python timings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.107 ms (7 allocations: 320 bytes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PyObject Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime x = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25.806 μs (3 allocations: 48 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime py\"1+1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyCall overhead is << 1ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30.295102 seconds (24.72 M allocations: 1.418 GiB, 5.16% gc time)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>VendorID</th><th>lpep_pickup_datetime</th><th>lpep_dropoff_datetime</th><th>store_and_fwd_flag</th><th>RatecodeID</th></tr><tr><th></th><th>Int64⍰</th><th>String</th><th>String</th><th>String⍰</th><th>Int64⍰</th></tr></thead><tbody><p>450,627 rows × 20 columns (omitted printing of 15 columns)</p><tr><th>1</th><td>1</td><td>2019-12-01 00:09:45</td><td>2019-12-01 00:10:59</td><td>N</td><td>1</td></tr><tr><th>2</th><td>2</td><td>2019-12-01 00:26:05</td><td>2019-12-01 00:31:30</td><td>N</td><td>1</td></tr><tr><th>3</th><td>2</td><td>2019-12-01 00:56:36</td><td>2019-12-01 00:59:38</td><td>N</td><td>1</td></tr><tr><th>4</th><td>2</td><td>2019-12-01 00:26:20</td><td>2019-12-01 00:40:19</td><td>N</td><td>1</td></tr><tr><th>5</th><td>2</td><td>2019-12-01 00:56:36</td><td>2019-12-01 00:59:56</td><td>N</td><td>1</td></tr><tr><th>6</th><td>1</td><td>2019-12-01 00:14:28</td><td>2019-12-01 00:19:39</td><td>N</td><td>1</td></tr><tr><th>7</th><td>1</td><td>2019-12-01 00:45:54</td><td>2019-12-01 00:52:46</td><td>N</td><td>1</td></tr><tr><th>8</th><td>2</td><td>2019-12-01 00:25:35</td><td>2019-12-01 01:04:08</td><td>N</td><td>1</td></tr><tr><th>9</th><td>1</td><td>2019-12-01 00:43:12</td><td>2019-12-01 00:56:44</td><td>N</td><td>1</td></tr><tr><th>10</th><td>2</td><td>2019-12-01 00:56:08</td><td>2019-12-01 01:05:11</td><td>N</td><td>1</td></tr><tr><th>11</th><td>2</td><td>2019-12-01 00:10:32</td><td>2019-12-01 00:34:48</td><td>N</td><td>1</td></tr><tr><th>12</th><td>2</td><td>2019-12-01 00:16:41</td><td>2019-12-01 00:20:42</td><td>N</td><td>1</td></tr><tr><th>13</th><td>2</td><td>2019-12-01 00:04:57</td><td>2019-12-01 00:06:22</td><td>N</td><td>1</td></tr><tr><th>14</th><td>2</td><td>2019-12-01 00:32:08</td><td>2019-12-01 00:44:06</td><td>N</td><td>1</td></tr><tr><th>15</th><td>2</td><td>2019-12-01 00:13:31</td><td>2019-12-01 00:22:38</td><td>N</td><td>1</td></tr><tr><th>16</th><td>2</td><td>2019-12-01 00:09:15</td><td>2019-12-01 00:14:28</td><td>N</td><td>1</td></tr><tr><th>17</th><td>2</td><td>2019-12-01 00:12:29</td><td>2019-12-01 00:27:39</td><td>N</td><td>1</td></tr><tr><th>18</th><td>1</td><td>2019-12-01 00:30:08</td><td>2019-12-01 00:33:24</td><td>N</td><td>1</td></tr><tr><th>19</th><td>1</td><td>2019-12-01 00:43:11</td><td>2019-12-01 00:51:47</td><td>N</td><td>1</td></tr><tr><th>20</th><td>1</td><td>2019-12-01 00:55:42</td><td>2019-12-01 00:57:50</td><td>N</td><td>1</td></tr><tr><th>21</th><td>2</td><td>2019-12-01 00:32:18</td><td>2019-12-01 00:33:01</td><td>N</td><td>5</td></tr><tr><th>22</th><td>2</td><td>2019-12-01 00:47:58</td><td>2019-12-01 00:59:03</td><td>N</td><td>1</td></tr><tr><th>23</th><td>2</td><td>2019-12-01 00:18:47</td><td>2019-12-01 00:31:28</td><td>N</td><td>1</td></tr><tr><th>24</th><td>1</td><td>2019-12-01 00:26:26</td><td>2019-12-01 00:45:41</td><td>N</td><td>1</td></tr><tr><th>25</th><td>2</td><td>2019-12-01 00:58:22</td><td>2019-12-01 01:03:44</td><td>N</td><td>1</td></tr><tr><th>26</th><td>2</td><td>2019-12-01 00:10:36</td><td>2019-12-01 00:19:25</td><td>N</td><td>1</td></tr><tr><th>27</th><td>2</td><td>2019-12-01 00:37:31</td><td>2019-12-01 01:01:51</td><td>N</td><td>1</td></tr><tr><th>28</th><td>2</td><td>2019-12-01 00:18:19</td><td>2019-12-01 00:34:26</td><td>N</td><td>1</td></tr><tr><th>29</th><td>2</td><td>2019-12-01 00:18:57</td><td>2019-12-01 00:19:00</td><td>N</td><td>5</td></tr><tr><th>30</th><td>2</td><td>2019-12-01 00:23:02</td><td>2019-12-01 00:32:27</td><td>N</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& VendorID & lpep\\_pickup\\_datetime & lpep\\_dropoff\\_datetime & store\\_and\\_fwd\\_flag & RatecodeID & \\\\\n",
       "\t\\hline\n",
       "\t& Int64⍰ & String & String & String⍰ & Int64⍰ & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 2019-12-01 00:09:45 & 2019-12-01 00:10:59 & N & 1 & $\\dots$ \\\\\n",
       "\t2 & 2 & 2019-12-01 00:26:05 & 2019-12-01 00:31:30 & N & 1 & $\\dots$ \\\\\n",
       "\t3 & 2 & 2019-12-01 00:56:36 & 2019-12-01 00:59:38 & N & 1 & $\\dots$ \\\\\n",
       "\t4 & 2 & 2019-12-01 00:26:20 & 2019-12-01 00:40:19 & N & 1 & $\\dots$ \\\\\n",
       "\t5 & 2 & 2019-12-01 00:56:36 & 2019-12-01 00:59:56 & N & 1 & $\\dots$ \\\\\n",
       "\t6 & 1 & 2019-12-01 00:14:28 & 2019-12-01 00:19:39 & N & 1 & $\\dots$ \\\\\n",
       "\t7 & 1 & 2019-12-01 00:45:54 & 2019-12-01 00:52:46 & N & 1 & $\\dots$ \\\\\n",
       "\t8 & 2 & 2019-12-01 00:25:35 & 2019-12-01 01:04:08 & N & 1 & $\\dots$ \\\\\n",
       "\t9 & 1 & 2019-12-01 00:43:12 & 2019-12-01 00:56:44 & N & 1 & $\\dots$ \\\\\n",
       "\t10 & 2 & 2019-12-01 00:56:08 & 2019-12-01 01:05:11 & N & 1 & $\\dots$ \\\\\n",
       "\t11 & 2 & 2019-12-01 00:10:32 & 2019-12-01 00:34:48 & N & 1 & $\\dots$ \\\\\n",
       "\t12 & 2 & 2019-12-01 00:16:41 & 2019-12-01 00:20:42 & N & 1 & $\\dots$ \\\\\n",
       "\t13 & 2 & 2019-12-01 00:04:57 & 2019-12-01 00:06:22 & N & 1 & $\\dots$ \\\\\n",
       "\t14 & 2 & 2019-12-01 00:32:08 & 2019-12-01 00:44:06 & N & 1 & $\\dots$ \\\\\n",
       "\t15 & 2 & 2019-12-01 00:13:31 & 2019-12-01 00:22:38 & N & 1 & $\\dots$ \\\\\n",
       "\t16 & 2 & 2019-12-01 00:09:15 & 2019-12-01 00:14:28 & N & 1 & $\\dots$ \\\\\n",
       "\t17 & 2 & 2019-12-01 00:12:29 & 2019-12-01 00:27:39 & N & 1 & $\\dots$ \\\\\n",
       "\t18 & 1 & 2019-12-01 00:30:08 & 2019-12-01 00:33:24 & N & 1 & $\\dots$ \\\\\n",
       "\t19 & 1 & 2019-12-01 00:43:11 & 2019-12-01 00:51:47 & N & 1 & $\\dots$ \\\\\n",
       "\t20 & 1 & 2019-12-01 00:55:42 & 2019-12-01 00:57:50 & N & 1 & $\\dots$ \\\\\n",
       "\t21 & 2 & 2019-12-01 00:32:18 & 2019-12-01 00:33:01 & N & 5 & $\\dots$ \\\\\n",
       "\t22 & 2 & 2019-12-01 00:47:58 & 2019-12-01 00:59:03 & N & 1 & $\\dots$ \\\\\n",
       "\t23 & 2 & 2019-12-01 00:18:47 & 2019-12-01 00:31:28 & N & 1 & $\\dots$ \\\\\n",
       "\t24 & 1 & 2019-12-01 00:26:26 & 2019-12-01 00:45:41 & N & 1 & $\\dots$ \\\\\n",
       "\t25 & 2 & 2019-12-01 00:58:22 & 2019-12-01 01:03:44 & N & 1 & $\\dots$ \\\\\n",
       "\t26 & 2 & 2019-12-01 00:10:36 & 2019-12-01 00:19:25 & N & 1 & $\\dots$ \\\\\n",
       "\t27 & 2 & 2019-12-01 00:37:31 & 2019-12-01 01:01:51 & N & 1 & $\\dots$ \\\\\n",
       "\t28 & 2 & 2019-12-01 00:18:19 & 2019-12-01 00:34:26 & N & 1 & $\\dots$ \\\\\n",
       "\t29 & 2 & 2019-12-01 00:18:57 & 2019-12-01 00:19:00 & N & 5 & $\\dots$ \\\\\n",
       "\t30 & 2 & 2019-12-01 00:23:02 & 2019-12-01 00:32:27 & N & 1 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "450627×20 DataFrame. Omitted printing of 17 columns\n",
       "│ Row    │ VendorID │ lpep_pickup_datetime │ lpep_dropoff_datetime │\n",
       "│        │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mString\u001b[39m               │ \u001b[90mString\u001b[39m                │\n",
       "├────────┼──────────┼──────────────────────┼───────────────────────┤\n",
       "│ 1      │ 1        │ 2019-12-01 00:09:45  │ 2019-12-01 00:10:59   │\n",
       "│ 2      │ 2        │ 2019-12-01 00:26:05  │ 2019-12-01 00:31:30   │\n",
       "│ 3      │ 2        │ 2019-12-01 00:56:36  │ 2019-12-01 00:59:38   │\n",
       "│ 4      │ 2        │ 2019-12-01 00:26:20  │ 2019-12-01 00:40:19   │\n",
       "│ 5      │ 2        │ 2019-12-01 00:56:36  │ 2019-12-01 00:59:56   │\n",
       "│ 6      │ 1        │ 2019-12-01 00:14:28  │ 2019-12-01 00:19:39   │\n",
       "│ 7      │ 1        │ 2019-12-01 00:45:54  │ 2019-12-01 00:52:46   │\n",
       "│ 8      │ 2        │ 2019-12-01 00:25:35  │ 2019-12-01 01:04:08   │\n",
       "│ 9      │ 1        │ 2019-12-01 00:43:12  │ 2019-12-01 00:56:44   │\n",
       "│ 10     │ 2        │ 2019-12-01 00:56:08  │ 2019-12-01 01:05:11   │\n",
       "⋮\n",
       "│ 450617 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:59:00  │ 2020-01-01 00:31:00   │\n",
       "│ 450618 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:14:00  │ 2019-12-31 23:45:00   │\n",
       "│ 450619 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:04:00  │ 2019-12-31 23:38:00   │\n",
       "│ 450620 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:11:00  │ 2019-12-31 23:27:00   │\n",
       "│ 450621 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:34:00  │ 2019-12-31 23:59:00   │\n",
       "│ 450622 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:46:00  │ 2020-01-01 00:03:00   │\n",
       "│ 450623 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:26:00  │ 2019-12-31 23:54:00   │\n",
       "│ 450624 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:02:00  │ 2019-12-31 23:16:00   │\n",
       "│ 450625 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:24:00  │ 2019-12-31 23:40:00   │\n",
       "│ 450626 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:16:00  │ 2019-12-31 23:37:00   │\n",
       "│ 450627 │ \u001b[90mmissing\u001b[39m  │ 2019-12-31 23:52:00  │ 2020-01-01 00:05:00   │"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time df = CSV.File(\"test_data.csv\") |> DataFrame # including compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  366.362 ms (1453154 allocations: 308.71 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime df = CSV.File(\"test_data.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  954.164 ms (1552638 allocations: 313.63 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime df = CSV.File(\"test_data.csv\", threaded=false) |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th></tr></thead><tbody><p>20 rows × 8 columns (omitted printing of 3 columns)</p><tr><th>1</th><td>VendorID</td><td>1.83345</td><td>1</td><td>2.0</td><td>2</td></tr><tr><th>2</th><td>lpep_pickup_datetime</td><td></td><td>2008-12-31 22:34:56</td><td></td><td>2035-09-02 17:17:47</td></tr><tr><th>3</th><td>lpep_dropoff_datetime</td><td></td><td>2008-12-31 22:42:10</td><td></td><td>2035-09-02 19:01:37</td></tr><tr><th>4</th><td>store_and_fwd_flag</td><td></td><td>N</td><td></td><td>Y</td></tr><tr><th>5</th><td>RatecodeID</td><td>1.10284</td><td>1</td><td>1.0</td><td>6</td></tr><tr><th>6</th><td>PULocationID</td><td>107.481</td><td>1</td><td>82.0</td><td>265</td></tr><tr><th>7</th><td>DOLocationID</td><td>128.446</td><td>1</td><td>129.0</td><td>265</td></tr><tr><th>8</th><td>passenger_count</td><td>1.31158</td><td>0</td><td>1.0</td><td>9</td></tr><tr><th>9</th><td>trip_distance</td><td>3.44502</td><td>-9436.33</td><td>1.94</td><td>77843.8</td></tr><tr><th>10</th><td>fare_amount</td><td>15.5867</td><td>-200.0</td><td>11.0</td><td>500.0</td></tr><tr><th>11</th><td>extra</td><td>0.888232</td><td>-4.5</td><td>0.5</td><td>8.25</td></tr><tr><th>12</th><td>mta_tax</td><td>0.439677</td><td>-0.5</td><td>0.5</td><td>3.55</td></tr><tr><th>13</th><td>tip_amount</td><td>0.949459</td><td>-90.5</td><td>0.0</td><td>441.0</td></tr><tr><th>14</th><td>tolls_amount</td><td>0.289563</td><td>0.0</td><td>0.0</td><td>48.0</td></tr><tr><th>15</th><td>ehail_fee</td><td></td><td></td><td></td><td></td></tr><tr><th>16</th><td>improvement_surcharge</td><td>0.270599</td><td>-0.3</td><td>0.3</td><td>0.3</td></tr><tr><th>17</th><td>total_amount</td><td>18.7367</td><td>-200.0</td><td>14.15</td><td>500.3</td></tr><tr><th>18</th><td>payment_type</td><td>1.477</td><td>1</td><td>1.0</td><td>5</td></tr><tr><th>19</th><td>trip_type</td><td>1.02323</td><td>1</td><td>1.0</td><td>2</td></tr><tr><th>20</th><td>congestion_surcharge</td><td>0.426469</td><td>-2.75</td><td>0.0</td><td>2.75</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& variable & mean & min & median & max & \\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & VendorID & 1.83345 & 1 & 2.0 & 2 & $\\dots$ \\\\\n",
       "\t2 & lpep\\_pickup\\_datetime &  & 2008-12-31 22:34:56 &  & 2035-09-02 17:17:47 & $\\dots$ \\\\\n",
       "\t3 & lpep\\_dropoff\\_datetime &  & 2008-12-31 22:42:10 &  & 2035-09-02 19:01:37 & $\\dots$ \\\\\n",
       "\t4 & store\\_and\\_fwd\\_flag &  & N &  & Y & $\\dots$ \\\\\n",
       "\t5 & RatecodeID & 1.10284 & 1 & 1.0 & 6 & $\\dots$ \\\\\n",
       "\t6 & PULocationID & 107.481 & 1 & 82.0 & 265 & $\\dots$ \\\\\n",
       "\t7 & DOLocationID & 128.446 & 1 & 129.0 & 265 & $\\dots$ \\\\\n",
       "\t8 & passenger\\_count & 1.31158 & 0 & 1.0 & 9 & $\\dots$ \\\\\n",
       "\t9 & trip\\_distance & 3.44502 & -9436.33 & 1.94 & 77843.8 & $\\dots$ \\\\\n",
       "\t10 & fare\\_amount & 15.5867 & -200.0 & 11.0 & 500.0 & $\\dots$ \\\\\n",
       "\t11 & extra & 0.888232 & -4.5 & 0.5 & 8.25 & $\\dots$ \\\\\n",
       "\t12 & mta\\_tax & 0.439677 & -0.5 & 0.5 & 3.55 & $\\dots$ \\\\\n",
       "\t13 & tip\\_amount & 0.949459 & -90.5 & 0.0 & 441.0 & $\\dots$ \\\\\n",
       "\t14 & tolls\\_amount & 0.289563 & 0.0 & 0.0 & 48.0 & $\\dots$ \\\\\n",
       "\t15 & ehail\\_fee &  &  &  &  & $\\dots$ \\\\\n",
       "\t16 & improvement\\_surcharge & 0.270599 & -0.3 & 0.3 & 0.3 & $\\dots$ \\\\\n",
       "\t17 & total\\_amount & 18.7367 & -200.0 & 14.15 & 500.3 & $\\dots$ \\\\\n",
       "\t18 & payment\\_type & 1.477 & 1 & 1.0 & 5 & $\\dots$ \\\\\n",
       "\t19 & trip\\_type & 1.02323 & 1 & 1.0 & 2 & $\\dots$ \\\\\n",
       "\t20 & congestion\\_surcharge & 0.426469 & -2.75 & 0.0 & 2.75 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "20×8 DataFrame. Omitted printing of 4 columns\n",
       "│ Row │ variable              │ mean     │ min                 │ median │\n",
       "│     │ \u001b[90mSymbol\u001b[39m                │ \u001b[90mUnion…\u001b[39m   │ \u001b[90mAny\u001b[39m                 │ \u001b[90mUnion…\u001b[39m │\n",
       "├─────┼───────────────────────┼──────────┼─────────────────────┼────────┤\n",
       "│ 1   │ VendorID              │ 1.83345  │ 1                   │ 2.0    │\n",
       "│ 2   │ lpep_pickup_datetime  │          │ 2008-12-31 22:34:56 │        │\n",
       "│ 3   │ lpep_dropoff_datetime │          │ 2008-12-31 22:42:10 │        │\n",
       "│ 4   │ store_and_fwd_flag    │          │ N                   │        │\n",
       "│ 5   │ RatecodeID            │ 1.10284  │ 1                   │ 1.0    │\n",
       "│ 6   │ PULocationID          │ 107.481  │ 1                   │ 82.0   │\n",
       "│ 7   │ DOLocationID          │ 128.446  │ 1                   │ 129.0  │\n",
       "│ 8   │ passenger_count       │ 1.31158  │ 0                   │ 1.0    │\n",
       "│ 9   │ trip_distance         │ 3.44502  │ -9436.33            │ 1.94   │\n",
       "│ 10  │ fare_amount           │ 15.5867  │ -200.0              │ 11.0   │\n",
       "│ 11  │ extra                 │ 0.888232 │ -4.5                │ 0.5    │\n",
       "│ 12  │ mta_tax               │ 0.439677 │ -0.5                │ 0.5    │\n",
       "│ 13  │ tip_amount            │ 0.949459 │ -90.5               │ 0.0    │\n",
       "│ 14  │ tolls_amount          │ 0.289563 │ 0.0                 │ 0.0    │\n",
       "│ 15  │ ehail_fee             │          │                     │        │\n",
       "│ 16  │ improvement_surcharge │ 0.270599 │ -0.3                │ 0.3    │\n",
       "│ 17  │ total_amount          │ 18.7367  │ -200.0              │ 14.15  │\n",
       "│ 18  │ payment_type          │ 1.477    │ 1                   │ 1.0    │\n",
       "│ 19  │ trip_type             │ 1.02323  │ 1                   │ 1.0    │\n",
       "│ 20  │ congestion_surcharge  │ 0.426469 │ -2.75               │ 0.0    │"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.003191 seconds (33.99 k allocations: 1.710 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time pydf = pd.read_csv(\"test_data.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject VendorID                 float64\n",
       "lpep_pickup_datetime      object\n",
       "lpep_dropoff_datetime     object\n",
       "store_and_fwd_flag        object\n",
       "RatecodeID               float64\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "passenger_count          float64\n",
       "trip_distance            float64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "ehail_fee                float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "payment_type             float64\n",
       "trip_type                float64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.881 s (9 allocations: 352 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime pydf = pd.read_csv(\"test_data.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python direct: 1.98s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Import in Julia is a factor of 2 faster (single-threaded). It uses multithreading as default, with gives an additional speedup of a factor 3 here (4-core machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  140.129 ms (450632 allocations: 24.07 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime DateTime.(df[!, :lpep_pickup_datetime], dateformat\"yyyy-mm-dd HH:MM:SS\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.407877 seconds (933.46 k allocations: 49.596 MiB, 4.91% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "450627-element Array{DateTime,1}:\n",
       " 2019-12-01T00:10:59\n",
       " 2019-12-01T00:31:30\n",
       " 2019-12-01T00:59:38\n",
       " 2019-12-01T00:40:19\n",
       " 2019-12-01T00:59:56\n",
       " 2019-12-01T00:19:39\n",
       " 2019-12-01T00:52:46\n",
       " 2019-12-01T01:04:08\n",
       " 2019-12-01T00:56:44\n",
       " 2019-12-01T01:05:11\n",
       " 2019-12-01T00:34:48\n",
       " 2019-12-01T00:20:42\n",
       " 2019-12-01T00:06:22\n",
       " ⋮                  \n",
       " 2020-01-01T00:06:00\n",
       " 2020-01-01T00:31:00\n",
       " 2019-12-31T23:45:00\n",
       " 2019-12-31T23:38:00\n",
       " 2019-12-31T23:27:00\n",
       " 2019-12-31T23:59:00\n",
       " 2020-01-01T00:03:00\n",
       " 2019-12-31T23:54:00\n",
       " 2019-12-31T23:16:00\n",
       " 2019-12-31T23:40:00\n",
       " 2019-12-31T23:37:00\n",
       " 2020-01-01T00:05:00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time begin\n",
    "    df[!, :lpep_pickup_datetime] = DateTime.(df[!, :lpep_pickup_datetime], \n",
    "        dateformat\"yyyy-mm-dd HH:MM:SS\");\n",
    "    df[!, :lpep_dropoff_datetime] = DateTime.(df[!, :lpep_dropoff_datetime], \n",
    "        dateformat\"yyyy-mm-dd HH:MM:SS\");\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  133.233 ms (12 allocations: 528 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime pd.to_datetime(pydf.lpep_pickup_datetime);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.331713 seconds (7.13 k allocations: 345.325 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject 0        2019-12-01 00:10:59\n",
       "1        2019-12-01 00:31:30\n",
       "2        2019-12-01 00:59:38\n",
       "3        2019-12-01 00:40:19\n",
       "4        2019-12-01 00:59:56\n",
       "                 ...        \n",
       "450622   2019-12-31 23:54:00\n",
       "450623   2019-12-31 23:16:00\n",
       "450624   2019-12-31 23:40:00\n",
       "450625   2019-12-31 23:37:00\n",
       "450626   2020-01-01 00:05:00\n",
       "Name: lpep_dropoff_datetime, Length: 450627, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time begin\n",
    "    pydf.lpep_pickup_datetime = pd.to_datetime(pydf.lpep_pickup_datetime);\n",
    "    pydf.lpep_dropoff_datetime = pd.to_datetime(pydf.lpep_dropoff_datetime);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python direct: 0.35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject VendorID                        float64\n",
       "lpep_pickup_datetime     datetime64[ns]\n",
       "lpep_dropoff_datetime    datetime64[ns]\n",
       "store_and_fwd_flag               object\n",
       "RatecodeID                      float64\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "ehail_fee                       float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "payment_type                    float64\n",
       "trip_type                       float64\n",
       "congestion_surcharge            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion speed is similar, but Python syntax is easier (no need to explicitly define datetime format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450627-element Array{Second,1}:\n",
       " 74 seconds  \n",
       " 325 seconds \n",
       " 182 seconds \n",
       " 839 seconds \n",
       " 200 seconds \n",
       " 311 seconds \n",
       " 412 seconds \n",
       " 2313 seconds\n",
       " 812 seconds \n",
       " 543 seconds \n",
       " 1456 seconds\n",
       " 241 seconds \n",
       " 85 seconds  \n",
       " ⋮           \n",
       " 540 seconds \n",
       " 1920 seconds\n",
       " 1860 seconds\n",
       " 2040 seconds\n",
       " 960 seconds \n",
       " 1500 seconds\n",
       " 1020 seconds\n",
       " 1680 seconds\n",
       " 840 seconds \n",
       " 960 seconds \n",
       " 1260 seconds\n",
       " 780 seconds "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[!, :drive_time] = Second.(df[!, :lpep_dropoff_datetime] .- df[!, :lpep_pickup_datetime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.940 ms (8 allocations: 3.44 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime df[!, :drive_time] = Second.(df[!, :lpep_dropoff_datetime] .- df[!, :lpep_pickup_datetime]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject 0        00:01:14\n",
       "1        00:05:25\n",
       "2        00:03:02\n",
       "3        00:13:59\n",
       "4        00:03:20\n",
       "           ...   \n",
       "450622   00:28:00\n",
       "450623   00:14:00\n",
       "450624   00:16:00\n",
       "450625   00:21:00\n",
       "450626   00:13:00\n",
       "Length: 450627, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf.drive_time = (pydf.lpep_dropoff_datetime - pydf.lpep_pickup_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14.310 ms (9 allocations: 400 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime pydf.drive_time = (pydf.lpep_dropoff_datetime - pydf.lpep_pickup_datetime);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python direct: 17ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450627-element Array{Float64,1}:\n",
       " Inf                 \n",
       "   8.208955223880597 \n",
       "   7.377049180327869 \n",
       "   3.58974358974359  \n",
       "   9.0               \n",
       "   5.454545454545454 \n",
       "   5.0               \n",
       "   4.0431266846361185\n",
       "   3.1132075471698113\n",
       "   3.7878787878787876\n",
       "   4.675324675324675 \n",
       "   6.617647058823529 \n",
       "  75.0               \n",
       "   ⋮                 \n",
       "   5.55036855036855  \n",
       "   2.9398034398034394\n",
       "   3.1742610837438425\n",
       "   2.40232268768146  \n",
       "   4.89202657807309  \n",
       "   2.398413666870043 \n",
       "   2.886944818304172 \n",
       "   4.875249500998004 \n",
       "  10.268722466960352 \n",
       "   2.916577540106952 \n",
       "  -5.020949720670392 \n",
       "   8.703703703703702 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[!, :price_per_mile] = df[!, :fare_amount] ./ df[!, :trip_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.657 ms (5 allocations: 3.44 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime df[!, :price_per_mile] = df[!, :fare_amount] ./ df[!, :trip_distance];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.022 ms (9 allocations: 368 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject 0               inf\n",
       "1          8.208955\n",
       "2          7.377049\n",
       "3          3.589744\n",
       "4          9.000000\n",
       "            ...    \n",
       "450622     4.875250\n",
       "450623    10.268722\n",
       "450624     2.916578\n",
       "450625    -5.020950\n",
       "450626     8.703704\n",
       "Length: 450627, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime pydf.price_per_mile = pydf.fare_amount / pydf.trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  29.183 ms (27 allocations: 7.31 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "450627-element Array{Union{Missing, Float64},1}:\n",
       "  Inf                    \n",
       " 3674.702264144405       \n",
       " 1599.864838235631       \n",
       "   37.22478632880233     \n",
       " 8104.083927575384       \n",
       "  234.81856574475168     \n",
       "  149.4131591025766      \n",
       "   58.004298919792745    \n",
       "   23.493076419549602    \n",
       "   45.16262255965407     \n",
       "  132.26738851310304     \n",
       "  749.182594758126       \n",
       "    3.7332419967990015e32\n",
       "    ⋮                    \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             \n",
       "     missing             "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime exp.(df[!, :fare_amount] ./ df[!, :trip_distance]) .+ df[!, :passenger_count].^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  26.390 ms (24 allocations: 928 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject 0                 inf\n",
       "1         3674.702264\n",
       "2         1599.864838\n",
       "3           37.224786\n",
       "4         8104.083928\n",
       "             ...     \n",
       "450622            NaN\n",
       "450623            NaN\n",
       "450624            NaN\n",
       "450625            NaN\n",
       "450626            NaN\n",
       "Length: 450627, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime np.exp(pydf.fare_amount / pydf.trip_distance) + pydf.passenger_count^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python direct: 28.5ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia is faster for the time distance, whereas Pandas is faster for the numerical calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>passenger_count</th><th>mean_distance</th><th>max_distance</th></tr><tr><th></th><th>Int64⍰</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>11 rows × 3 columns</p><tr><th>1</th><td>1</td><td>2.58961</td><td>333.3</td></tr><tr><th>2</th><td>5</td><td>2.60981</td><td>38.89</td></tr><tr><th>3</th><td>2</td><td>2.89825</td><td>48.78</td></tr><tr><th>4</th><td>6</td><td>2.41251</td><td>27.78</td></tr><tr><th>5</th><td>3</td><td>2.84961</td><td>34.1</td></tr><tr><th>6</th><td>4</td><td>2.6318</td><td>69.86</td></tr><tr><th>7</th><td>0</td><td>2.27189</td><td>20.67</td></tr><tr><th>8</th><td>7</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>8</td><td>2.1075</td><td>11.77</td></tr><tr><th>10</th><td>9</td><td>0.04</td><td>0.08</td></tr><tr><th>11</th><td>missing</td><td>6.74247</td><td>77843.8</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& passenger\\_count & mean\\_distance & max\\_distance\\\\\n",
       "\t\\hline\n",
       "\t& Int64⍰ & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 2.58961 & 333.3 \\\\\n",
       "\t2 & 5 & 2.60981 & 38.89 \\\\\n",
       "\t3 & 2 & 2.89825 & 48.78 \\\\\n",
       "\t4 & 6 & 2.41251 & 27.78 \\\\\n",
       "\t5 & 3 & 2.84961 & 34.1 \\\\\n",
       "\t6 & 4 & 2.6318 & 69.86 \\\\\n",
       "\t7 & 0 & 2.27189 & 20.67 \\\\\n",
       "\t8 & 7 & 0.0 & 0.0 \\\\\n",
       "\t9 & 8 & 2.1075 & 11.77 \\\\\n",
       "\t10 & 9 & 0.04 & 0.08 \\\\\n",
       "\t11 &  & 6.74247 & 77843.8 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "11×3 DataFrame\n",
       "│ Row │ passenger_count │ mean_distance │ max_distance │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m          │ \u001b[90mFloat64\u001b[39m       │ \u001b[90mFloat64\u001b[39m      │\n",
       "├─────┼─────────────────┼───────────────┼──────────────┤\n",
       "│ 1   │ 1               │ 2.58961       │ 333.3        │\n",
       "│ 2   │ 5               │ 2.60981       │ 38.89        │\n",
       "│ 3   │ 2               │ 2.89825       │ 48.78        │\n",
       "│ 4   │ 6               │ 2.41251       │ 27.78        │\n",
       "│ 5   │ 3               │ 2.84961       │ 34.1         │\n",
       "│ 6   │ 4               │ 2.6318        │ 69.86        │\n",
       "│ 7   │ 0               │ 2.27189       │ 20.67        │\n",
       "│ 8   │ 7               │ 0.0           │ 0.0          │\n",
       "│ 9   │ 8               │ 2.1075        │ 11.77        │\n",
       "│ 10  │ 9               │ 0.04          │ 0.08         │\n",
       "│ 11  │ \u001b[90mmissing\u001b[39m         │ 6.74247       │ 77843.8      │"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by(df, :passenger_count, (mean_distance=:trip_distance=>mean), \n",
    "    (max_distance=:trip_distance=>maximum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  27.963 ms (250 allocations: 14.33 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime by(df, :passenger_count, (mean_distance=:trip_distance=>mean), \n",
    "    (max_distance=:trip_distance=>maximum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>max_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2.271892</td>\n",
       "      <td>20.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.589612</td>\n",
       "      <td>333.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2.898245</td>\n",
       "      <td>48.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.849613</td>\n",
       "      <td>34.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2.631798</td>\n",
       "      <td>69.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>2.609807</td>\n",
       "      <td>38.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>2.412509</td>\n",
       "      <td>27.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>2.107500</td>\n",
       "      <td>11.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PyObject                  mean_distance  max_distance\n",
       "passenger_count                             \n",
       "0.0                   2.271892         20.67\n",
       "1.0                   2.589612        333.30\n",
       "2.0                   2.898245         48.78\n",
       "3.0                   2.849613         34.10\n",
       "4.0                   2.631798         69.86\n",
       "5.0                   2.609807         38.89\n",
       "6.0                   2.412509         27.78\n",
       "7.0                   0.000000          0.00\n",
       "8.0                   2.107500         11.77\n",
       "9.0                   0.040000          0.08"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf.groupby(\"passenger_count\").agg(mean_distance=(\"trip_distance\", \"mean\"), \n",
    "    max_distance=(\"trip_distance\", \"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  43.697 ms (47 allocations: 2.13 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime pydf.groupby(\"passenger_count\").agg(mean_distance=(\"trip_distance\", \"mean\"), \n",
    "    max_distance=(\"trip_distance\", \"max\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  43.933 ms (54 allocations: 2.47 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime pydf.groupby(\"passenger_count\").agg(mean_distance=(\"trip_distance\", np.mean), \n",
    "    max_distance=(\"trip_distance\", np.max));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python direct: 36.4ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby-Aggregation is faster in Julia (and has shorter syntax)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myfunc (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myfunc(a, b, c)\n",
    "    if a === missing\n",
    "        return zero(a)\n",
    "    elseif round(Int, a) % 2 == 0\n",
    "        return 2a + b*c\n",
    "    else\n",
    "        return a*b + 2c\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450627-element Array{Union{Missing, Float64},1}:\n",
       "  6.0     \n",
       " 11.67    \n",
       "  9.61    \n",
       " 31.9     \n",
       "  9.5     \n",
       " 13.1     \n",
       " 16.5     \n",
       " 67.42    \n",
       " 38.3     \n",
       " 22.64    \n",
       " 55.25    \n",
       "  9.68    \n",
       "  6.04    \n",
       "  ⋮       \n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing\n",
       "   missing"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[!, :myfunc] = myfunc.(df.passenger_count, df.trip_distance, df.fare_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.296 ms (14 allocations: 7.31 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime df[!, :myfunc] = myfunc.(df.passenger_count, df.trip_distance, df.fare_amount);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450627, 23)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = first(df, 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.360 μs (11 allocations: 8.19 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime df2[!, :myfunc] = myfunc.(df2.passenger_count, df2.trip_distance, df2.fare_amount);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "import numpy as np\n",
    "def myfunc_py(a, b, c):\n",
    "    if a is np.nan:\n",
    "        return 0\n",
    "    elif round(a) % 2 == 0:\n",
    "        return 2*a + b*c\n",
    "    else:\n",
    "        return a*b + 2*c\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  43.153 μs (3 allocations: 48 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime py\"myfunc_py(1, 2, 3)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python direct: 849ns - significantly faster than with PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydf2 = pydf.head(1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  242.319 ms (35 allocations: 1.70 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject 0       6.00\n",
       "1      11.67\n",
       "2       9.61\n",
       "3      31.90\n",
       "4       9.50\n",
       "       ...  \n",
       "995    26.11\n",
       "996    34.83\n",
       "997    46.70\n",
       "998    76.50\n",
       "999    14.43\n",
       "Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime pydf2.myfunc = pydf2.apply(py\"lambda x: myfunc_py(x.passenger_count, x.trip_distance, x.fare_amount)\", \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  241.970 ms (7 allocations: 208 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject 0       6.00\n",
       "1      11.67\n",
       "2       9.61\n",
       "3      31.90\n",
       "4       9.50\n",
       "       ...  \n",
       "995    26.11\n",
       "996    34.83\n",
       "997    46.70\n",
       "998    76.50\n",
       "999    14.43\n",
       "Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime py\"$pydf2.apply(lambda x: myfunc_py(x.passenger_count, x.trip_distance, x.fare_amount), axis=1)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python direct: 201ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia is here ca. 20,000 times faster than Python/ Pandas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_iter (generic function with 1 method)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function df_iter(df)\n",
    "    result = 0\n",
    "    last_passenger = 0\n",
    "    for row in eachrow(df)\n",
    "        if row.passenger_count === missing\n",
    "            continue\n",
    "        end\n",
    "        result += row.passenger_count * last_passenger\n",
    "        last_passenger = row.passenger_count\n",
    "    end\n",
    "    result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables\n",
      "  #self#\u001b[36m::Core.Compiler.Const(df_iter, false)\u001b[39m\n",
      "  df\u001b[36m::DataFrame\u001b[39m\n",
      "  result\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  last_passenger\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  @_5\u001b[33m\u001b[1m::Union{Nothing, Tuple{DataFrameRow{DataFrame,DataFrames.Index},Tuple{Base.OneTo{Int64},Int64}}}\u001b[22m\u001b[39m\n",
      "  row\u001b[36m::DataFrameRow{DataFrame,DataFrames.Index}\u001b[39m\n",
      "\n",
      "Body\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m       (result = 0)\n",
      "\u001b[90m│  \u001b[39m       (last_passenger = 0)\n",
      "\u001b[90m│  \u001b[39m %3  = Main.eachrow(df)\u001b[36m::DataFrames.DataFrameRows{DataFrame,DataFrames.Index}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_5 = Base.iterate(%3))\n",
      "\u001b[90m│  \u001b[39m %5  = (@_5 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %6  = Base.not_int(%5)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #7 if not %6\n",
      "\u001b[90m2 ┄\u001b[39m %8  = @_5::Tuple{DataFrameRow{DataFrame,DataFrames.Index},Tuple{Base.OneTo{Int64},Int64}}\u001b[36m::Tuple{DataFrameRow{DataFrame,DataFrames.Index},Tuple{Base.OneTo{Int64},Int64}}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (row = Core.getfield(%8, 1))\n",
      "\u001b[90m│  \u001b[39m %10 = Core.getfield(%8, 2)\u001b[36m::Tuple{Base.OneTo{Int64},Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %11 = Base.getproperty(row, :passenger_count)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %12 = (%11 === Main.missing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %12\n",
      "\u001b[90m3 ─\u001b[39m       goto #5\n",
      "\u001b[90m4 ─\u001b[39m %15 = result\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %16 = Base.getproperty(row, :passenger_count)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %17 = (%16 * last_passenger)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (result = %15 + %17)\n",
      "\u001b[90m└──\u001b[39m       (last_passenger = Base.getproperty(row, :passenger_count))\n",
      "\u001b[90m5 ┄\u001b[39m       (@_5 = Base.iterate(%3, %10))\n",
      "\u001b[90m│  \u001b[39m %21 = (@_5 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %22 = Base.not_int(%21)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #7 if not %22\n",
      "\u001b[90m6 ─\u001b[39m       goto #2\n",
      "\u001b[90m7 ┄\u001b[39m       return result\n"
     ]
    }
   ],
   "source": [
    "@code_warntype df_iter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  267.498 ms (3149642 allocations: 54.94 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "715957"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime df_iter($df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_iter2 (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function df_iter2(df)\n",
    "    result = 0\n",
    "    last_passenger = 0\n",
    "    for row in eachrow(df)\n",
    "        if row.passenger_count === missing\n",
    "            continue\n",
    "        end\n",
    "        passenger = row.passenger_count:: Int\n",
    "        result += passenger * last_passenger\n",
    "        last_passenger = passenger\n",
    "    end\n",
    "    result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables\n",
      "  #self#\u001b[36m::Core.Compiler.Const(df_iter2, false)\u001b[39m\n",
      "  df\u001b[36m::DataFrame\u001b[39m\n",
      "  result\u001b[36m::Int64\u001b[39m\n",
      "  last_passenger\u001b[36m::Int64\u001b[39m\n",
      "  @_5\u001b[33m\u001b[1m::Union{Nothing, Tuple{DataFrameRow{DataFrame,DataFrames.Index},Tuple{Base.OneTo{Int64},Int64}}}\u001b[22m\u001b[39m\n",
      "  row\u001b[36m::DataFrameRow{DataFrame,DataFrames.Index}\u001b[39m\n",
      "  passenger\u001b[36m::Int64\u001b[39m\n",
      "\n",
      "Body\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m       (result = 0)\n",
      "\u001b[90m│  \u001b[39m       (last_passenger = 0)\n",
      "\u001b[90m│  \u001b[39m %3  = Main.eachrow(df)\u001b[36m::DataFrames.DataFrameRows{DataFrame,DataFrames.Index}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_5 = Base.iterate(%3))\n",
      "\u001b[90m│  \u001b[39m %5  = (@_5 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %6  = Base.not_int(%5)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #7 if not %6\n",
      "\u001b[90m2 ┄\u001b[39m       Core.NewvarNode(:(passenger))\n",
      "\u001b[90m│  \u001b[39m %9  = @_5::Tuple{DataFrameRow{DataFrame,DataFrames.Index},Tuple{Base.OneTo{Int64},Int64}}\u001b[36m::Tuple{DataFrameRow{DataFrame,DataFrames.Index},Tuple{Base.OneTo{Int64},Int64}}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (row = Core.getfield(%9, 1))\n",
      "\u001b[90m│  \u001b[39m %11 = Core.getfield(%9, 2)\u001b[36m::Tuple{Base.OneTo{Int64},Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %12 = Base.getproperty(row, :passenger_count)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %13 = (%12 === Main.missing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %13\n",
      "\u001b[90m3 ─\u001b[39m       goto #5\n",
      "\u001b[90m4 ─\u001b[39m %16 = Base.getproperty(row, :passenger_count)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (passenger = Core.typeassert(%16, Main.Int))\n",
      "\u001b[90m│  \u001b[39m %18 = result\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %19 = (passenger * last_passenger)\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (result = %18 + %19)\n",
      "\u001b[90m└──\u001b[39m       (last_passenger = passenger)\n",
      "\u001b[90m5 ┄\u001b[39m       (@_5 = Base.iterate(%3, %11))\n",
      "\u001b[90m│  \u001b[39m %23 = (@_5 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %24 = Base.not_int(%23)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #7 if not %24\n",
      "\u001b[90m6 ─\u001b[39m       goto #2\n",
      "\u001b[90m7 ┄\u001b[39m       return result\n"
     ]
    }
   ],
   "source": [
    "@code_warntype df_iter2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  158.853 ms (2070664 allocations: 38.47 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "715957"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime df_iter2($df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A speedup of a factor of 2 by type assertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_iter3 (generic function with 1 method)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function df_iter3(passengers)\n",
    "    result = 0\n",
    "    last_passenger = 0\n",
    "    for row in passengers\n",
    "        if row === missing\n",
    "            continue\n",
    "        end\n",
    "        passenger = row\n",
    "        result += passenger * last_passenger\n",
    "        last_passenger = passenger\n",
    "    end\n",
    "    result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.644 ms (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "715957"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime df_iter3(df[!, :passenger_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_iter4 (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function df_iter4(passengers)\n",
    "    result = 0\n",
    "    last_passenger = 0\n",
    "    for row in skipmissing(passengers)\n",
    "        passenger = row\n",
    "        result += passenger * last_passenger\n",
    "        last_passenger = passenger\n",
    "    end\n",
    "    result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  938.002 μs (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "715957"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime df_iter4(df[!, :passenger_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping directly on arrays (extracted from df columns) gives a speedup of 100!\n",
    "\n",
    "Due to type instability, `eachrow` should be avoided in performance-critical code. Instead, use looping over column arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "def pydf_iter(df):\n",
    "    result = 0\n",
    "    last_passenger = 0\n",
    "    for row in df.itertuples(): # much faster than df.iterrows()\n",
    "        if np.isnan(row.passenger_count):\n",
    "            continue\n",
    "        result += row.passenger_count * last_passenger\n",
    "        last_passenger = row.passenger_count\n",
    "    return result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function pydf_iter at 0x7f8d00cdd4d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf_iter = py\"pydf_iter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  18.649 s (3 allocations: 48 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "715957.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime pydf_iter($pydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def pydf_iter2(passengers):\n",
    "    result = 0\n",
    "    last_passenger = 0\n",
    "    for row in passengers:\n",
    "        if np.isnan(row):\n",
    "            continue\n",
    "        result += row * last_passenger\n",
    "        last_passenger = row\n",
    "    return result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject CPUDispatcher(<function pydf_iter2 at 0x7f8d08d28ef0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf_iter2 = py\"pydf_iter2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.733 ms (41 allocations: 3.44 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "715957.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime pydf_iter2(pydf.passenger_count.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in the primitive (not type-stable) implementation, Julia is a factor of 50 faster than Python. When using loops over column arrays, Julia is a factor of 10,000 faster than Python.\n",
    "\n",
    "Using a Numba JIT compiled function on a Numpy array is \"only\" a factor of 3 slower than the Julia array loop implementation and faster than the (type unstable) Julia `eachrow` implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.355 s (11493266 allocations: 303.70 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime sort(df, (:passenger_count, :lpep_pickup_datetime), rev=(true, false));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `sort` creates a copy of the DataFrame, `sort!` does in-place sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  356.858 ms (7 allocations: 208 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime py\"$pydf.sort_values(['passenger_count', 'lpep_pickup_datetime'], ascending=[False, True])\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting is significantly faster in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas slicing syntax corresponds to Julia filter function. `missing` data must be explicitly treated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  202.057 ms (2070785 allocations: 43.70 MiB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>VendorID</th><th>lpep_pickup_datetime</th><th>lpep_dropoff_datetime</th><th>store_and_fwd_flag</th><th>RatecodeID</th></tr><tr><th></th><th>Int64⍰</th><th>DateTime</th><th>DateTime</th><th>String⍰</th><th>Int64⍰</th></tr></thead><tbody><p>26,698 rows × 23 columns (omitted printing of 18 columns)</p><tr><th>1</th><td>2</td><td>2019-12-01T00:29:25</td><td>2019-12-01T00:31:31</td><td>N</td><td>1</td></tr><tr><th>2</th><td>2</td><td>2019-12-01T00:37:10</td><td>2019-12-01T00:42:05</td><td>N</td><td>1</td></tr><tr><th>3</th><td>2</td><td>2019-12-01T00:14:09</td><td>2019-12-01T00:26:42</td><td>N</td><td>1</td></tr><tr><th>4</th><td>2</td><td>2019-12-01T00:07:27</td><td>2019-12-01T00:22:18</td><td>N</td><td>1</td></tr><tr><th>5</th><td>2</td><td>2019-12-01T00:33:06</td><td>2019-12-01T00:40:06</td><td>N</td><td>1</td></tr><tr><th>6</th><td>2</td><td>2019-12-01T00:58:59</td><td>2019-12-01T01:06:07</td><td>N</td><td>1</td></tr><tr><th>7</th><td>2</td><td>2019-12-01T00:07:04</td><td>2019-12-01T00:13:18</td><td>N</td><td>1</td></tr><tr><th>8</th><td>2</td><td>2019-12-01T00:53:50</td><td>2019-12-01T01:02:58</td><td>N</td><td>1</td></tr><tr><th>9</th><td>2</td><td>2019-12-01T00:53:19</td><td>2019-12-01T00:57:37</td><td>N</td><td>1</td></tr><tr><th>10</th><td>2</td><td>2019-12-01T00:09:07</td><td>2019-12-01T00:26:51</td><td>N</td><td>5</td></tr><tr><th>11</th><td>2</td><td>2019-12-01T00:01:47</td><td>2019-12-01T00:05:35</td><td>N</td><td>1</td></tr><tr><th>12</th><td>2</td><td>2019-12-01T00:26:51</td><td>2019-12-01T00:33:30</td><td>N</td><td>1</td></tr><tr><th>13</th><td>2</td><td>2019-12-01T00:48:14</td><td>2019-12-01T01:05:54</td><td>N</td><td>1</td></tr><tr><th>14</th><td>1</td><td>2019-12-01T00:03:50</td><td>2019-12-01T00:10:55</td><td>N</td><td>1</td></tr><tr><th>15</th><td>2</td><td>2019-12-01T00:43:14</td><td>2019-12-01T00:45:31</td><td>N</td><td>1</td></tr><tr><th>16</th><td>2</td><td>2019-12-01T00:46:07</td><td>2019-12-01T01:21:01</td><td>N</td><td>1</td></tr><tr><th>17</th><td>2</td><td>2019-12-01T00:16:21</td><td>2019-12-01T00:34:00</td><td>N</td><td>1</td></tr><tr><th>18</th><td>2</td><td>2019-12-01T00:09:24</td><td>2019-12-02T00:00:00</td><td>N</td><td>1</td></tr><tr><th>19</th><td>2</td><td>2019-12-01T00:08:31</td><td>2019-12-01T00:11:12</td><td>N</td><td>1</td></tr><tr><th>20</th><td>2</td><td>2019-12-01T00:30:30</td><td>2019-12-01T00:35:51</td><td>N</td><td>1</td></tr><tr><th>21</th><td>2</td><td>2019-12-01T00:04:48</td><td>2019-12-01T00:17:13</td><td>N</td><td>1</td></tr><tr><th>22</th><td>1</td><td>2019-12-01T00:10:59</td><td>2019-12-01T00:14:33</td><td>N</td><td>1</td></tr><tr><th>23</th><td>2</td><td>2019-12-01T00:50:48</td><td>2019-12-01T01:00:28</td><td>N</td><td>1</td></tr><tr><th>24</th><td>2</td><td>2019-12-01T00:14:04</td><td>2019-12-01T00:22:21</td><td>N</td><td>1</td></tr><tr><th>25</th><td>2</td><td>2019-12-01T00:43:12</td><td>2019-12-01T00:43:15</td><td>N</td><td>5</td></tr><tr><th>26</th><td>1</td><td>2019-12-01T00:34:17</td><td>2019-12-01T00:47:08</td><td>Y</td><td>1</td></tr><tr><th>27</th><td>2</td><td>2019-12-01T01:40:55</td><td>2019-12-01T01:55:26</td><td>N</td><td>1</td></tr><tr><th>28</th><td>2</td><td>2019-12-01T01:27:46</td><td>2019-12-01T01:41:38</td><td>N</td><td>1</td></tr><tr><th>29</th><td>2</td><td>2019-12-01T01:47:50</td><td>2019-12-01T01:56:55</td><td>N</td><td>1</td></tr><tr><th>30</th><td>2</td><td>2019-12-01T01:46:20</td><td>2019-12-01T02:01:31</td><td>N</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& VendorID & lpep\\_pickup\\_datetime & lpep\\_dropoff\\_datetime & store\\_and\\_fwd\\_flag & RatecodeID & \\\\\n",
       "\t\\hline\n",
       "\t& Int64⍰ & DateTime & DateTime & String⍰ & Int64⍰ & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2 & 2019-12-01T00:29:25 & 2019-12-01T00:31:31 & N & 1 & $\\dots$ \\\\\n",
       "\t2 & 2 & 2019-12-01T00:37:10 & 2019-12-01T00:42:05 & N & 1 & $\\dots$ \\\\\n",
       "\t3 & 2 & 2019-12-01T00:14:09 & 2019-12-01T00:26:42 & N & 1 & $\\dots$ \\\\\n",
       "\t4 & 2 & 2019-12-01T00:07:27 & 2019-12-01T00:22:18 & N & 1 & $\\dots$ \\\\\n",
       "\t5 & 2 & 2019-12-01T00:33:06 & 2019-12-01T00:40:06 & N & 1 & $\\dots$ \\\\\n",
       "\t6 & 2 & 2019-12-01T00:58:59 & 2019-12-01T01:06:07 & N & 1 & $\\dots$ \\\\\n",
       "\t7 & 2 & 2019-12-01T00:07:04 & 2019-12-01T00:13:18 & N & 1 & $\\dots$ \\\\\n",
       "\t8 & 2 & 2019-12-01T00:53:50 & 2019-12-01T01:02:58 & N & 1 & $\\dots$ \\\\\n",
       "\t9 & 2 & 2019-12-01T00:53:19 & 2019-12-01T00:57:37 & N & 1 & $\\dots$ \\\\\n",
       "\t10 & 2 & 2019-12-01T00:09:07 & 2019-12-01T00:26:51 & N & 5 & $\\dots$ \\\\\n",
       "\t11 & 2 & 2019-12-01T00:01:47 & 2019-12-01T00:05:35 & N & 1 & $\\dots$ \\\\\n",
       "\t12 & 2 & 2019-12-01T00:26:51 & 2019-12-01T00:33:30 & N & 1 & $\\dots$ \\\\\n",
       "\t13 & 2 & 2019-12-01T00:48:14 & 2019-12-01T01:05:54 & N & 1 & $\\dots$ \\\\\n",
       "\t14 & 1 & 2019-12-01T00:03:50 & 2019-12-01T00:10:55 & N & 1 & $\\dots$ \\\\\n",
       "\t15 & 2 & 2019-12-01T00:43:14 & 2019-12-01T00:45:31 & N & 1 & $\\dots$ \\\\\n",
       "\t16 & 2 & 2019-12-01T00:46:07 & 2019-12-01T01:21:01 & N & 1 & $\\dots$ \\\\\n",
       "\t17 & 2 & 2019-12-01T00:16:21 & 2019-12-01T00:34:00 & N & 1 & $\\dots$ \\\\\n",
       "\t18 & 2 & 2019-12-01T00:09:24 & 2019-12-02T00:00:00 & N & 1 & $\\dots$ \\\\\n",
       "\t19 & 2 & 2019-12-01T00:08:31 & 2019-12-01T00:11:12 & N & 1 & $\\dots$ \\\\\n",
       "\t20 & 2 & 2019-12-01T00:30:30 & 2019-12-01T00:35:51 & N & 1 & $\\dots$ \\\\\n",
       "\t21 & 2 & 2019-12-01T00:04:48 & 2019-12-01T00:17:13 & N & 1 & $\\dots$ \\\\\n",
       "\t22 & 1 & 2019-12-01T00:10:59 & 2019-12-01T00:14:33 & N & 1 & $\\dots$ \\\\\n",
       "\t23 & 2 & 2019-12-01T00:50:48 & 2019-12-01T01:00:28 & N & 1 & $\\dots$ \\\\\n",
       "\t24 & 2 & 2019-12-01T00:14:04 & 2019-12-01T00:22:21 & N & 1 & $\\dots$ \\\\\n",
       "\t25 & 2 & 2019-12-01T00:43:12 & 2019-12-01T00:43:15 & N & 5 & $\\dots$ \\\\\n",
       "\t26 & 1 & 2019-12-01T00:34:17 & 2019-12-01T00:47:08 & Y & 1 & $\\dots$ \\\\\n",
       "\t27 & 2 & 2019-12-01T01:40:55 & 2019-12-01T01:55:26 & N & 1 & $\\dots$ \\\\\n",
       "\t28 & 2 & 2019-12-01T01:27:46 & 2019-12-01T01:41:38 & N & 1 & $\\dots$ \\\\\n",
       "\t29 & 2 & 2019-12-01T01:47:50 & 2019-12-01T01:56:55 & N & 1 & $\\dots$ \\\\\n",
       "\t30 & 2 & 2019-12-01T01:46:20 & 2019-12-01T02:01:31 & N & 1 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "26698×23 DataFrame. Omitted printing of 20 columns\n",
       "│ Row   │ VendorID │ lpep_pickup_datetime │ lpep_dropoff_datetime │\n",
       "│       │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mDateTime\u001b[39m             │ \u001b[90mDateTime\u001b[39m              │\n",
       "├───────┼──────────┼──────────────────────┼───────────────────────┤\n",
       "│ 1     │ 2        │ 2019-12-01T00:29:25  │ 2019-12-01T00:31:31   │\n",
       "│ 2     │ 2        │ 2019-12-01T00:37:10  │ 2019-12-01T00:42:05   │\n",
       "│ 3     │ 2        │ 2019-12-01T00:14:09  │ 2019-12-01T00:26:42   │\n",
       "│ 4     │ 2        │ 2019-12-01T00:07:27  │ 2019-12-01T00:22:18   │\n",
       "│ 5     │ 2        │ 2019-12-01T00:33:06  │ 2019-12-01T00:40:06   │\n",
       "│ 6     │ 2        │ 2019-12-01T00:58:59  │ 2019-12-01T01:06:07   │\n",
       "│ 7     │ 2        │ 2019-12-01T00:07:04  │ 2019-12-01T00:13:18   │\n",
       "│ 8     │ 2        │ 2019-12-01T00:53:50  │ 2019-12-01T01:02:58   │\n",
       "│ 9     │ 2        │ 2019-12-01T00:53:19  │ 2019-12-01T00:57:37   │\n",
       "│ 10    │ 2        │ 2019-12-01T00:09:07  │ 2019-12-01T00:26:51   │\n",
       "⋮\n",
       "│ 26688 │ 2        │ 2019-12-31T23:31:03  │ 2019-12-31T23:48:52   │\n",
       "│ 26689 │ 2        │ 2019-12-31T23:22:05  │ 2019-12-31T23:25:46   │\n",
       "│ 26690 │ 2        │ 2019-12-31T23:28:49  │ 2019-12-31T23:38:56   │\n",
       "│ 26691 │ 1        │ 2019-12-31T23:14:48  │ 2019-12-31T23:38:06   │\n",
       "│ 26692 │ 1        │ 2019-12-31T23:52:17  │ 2019-12-31T23:58:54   │\n",
       "│ 26693 │ 1        │ 2019-12-31T23:38:04  │ 2019-12-31T23:44:02   │\n",
       "│ 26694 │ 2        │ 2019-12-31T23:05:36  │ 2019-12-31T23:14:21   │\n",
       "│ 26695 │ 2        │ 2019-12-31T23:23:27  │ 2019-12-31T23:33:17   │\n",
       "│ 26696 │ 2        │ 2019-12-31T23:51:51  │ 2020-01-01T00:10:29   │\n",
       "│ 26697 │ 2        │ 2019-12-31T23:48:11  │ 2019-12-31T23:59:23   │\n",
       "│ 26698 │ 2        │ 2019-12-31T23:18:35  │ 2019-12-31T23:22:26   │"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime filter(df) do x\n",
    "    !ismissing(x.passenger_count) && x.passenger_count == 2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15.476 ms (138 allocations: 4.85 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime df[.!ismissing.(df.passenger_count) .& (df.passenger_count .== 2), :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing syntax is much faster than filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15.211 ms (9 allocations: 240 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime py\"$pydf[$pydf.passenger_count == 2]\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia and Pandas have similar speed, maybe Julia is slightly faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling LibPQ [194296ae-ab2e-5f79-8cd4-7183a0a5a0d1]\n",
      "└ @ Base loading.jl:1273\n"
     ]
    }
   ],
   "source": [
    "using LibPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"postgres://postgres:python_tutorial_5432@192.168.1.24:15432/postgres\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_str = \"postgres://postgres:python_tutorial_5432@192.168.1.24:15432/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostgreSQL connection (CONNECTION_OK) with parameters:\n",
       "  user = postgres\n",
       "  password = ********************\n",
       "  dbname = postgres\n",
       "  host = 192.168.1.24\n",
       "  port = 15432\n",
       "  client_encoding = UTF8\n",
       "  options = -c DateStyle=ISO,YMD -c IntervalStyle=iso_8601 -c TimeZone=UTC\n",
       "  application_name = LibPQ.jl\n",
       "  sslmode = prefer\n",
       "  sslcompression = 0\n",
       "  gssencmode = disable\n",
       "  target_session_attrs = any"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = LibPQ.Connection(con_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'sqlalchemy' from '/opt/conda/lib/python3.7/site-packages/sqlalchemy/__init__.py'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlalchemy = pyimport(\"sqlalchemy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Engine(postgres://postgres:***@192.168.1.24:15432/postgres)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyengine = sqlalchemy.create_engine(con_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Table for Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23-element Array{Symbol,1}:\n",
       " :VendorID             \n",
       " :lpep_pickup_datetime \n",
       " :lpep_dropoff_datetime\n",
       " :store_and_fwd_flag   \n",
       " :RatecodeID           \n",
       " :PULocationID         \n",
       " :DOLocationID         \n",
       " :passenger_count      \n",
       " :trip_distance        \n",
       " :fare_amount          \n",
       " :extra                \n",
       " :mta_tax              \n",
       " :tip_amount           \n",
       " :tolls_amount         \n",
       " :ehail_fee            \n",
       " :improvement_surcharge\n",
       " :total_amount         \n",
       " :payment_type         \n",
       " :trip_type            \n",
       " :congestion_surcharge \n",
       " :drive_time           \n",
       " :price_per_mile       \n",
       " :myfunc               "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[:, [:lpep_pickup_datetime, :passenger_count, :trip_distance]];\n",
    "#dropmissing!(df_sample);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>lpep_pickup_datetime</th><th>passenger_count</th><th>trip_distance</th></tr><tr><th></th><th>DateTime</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>2019-12-01T00:09:45</td><td>1</td><td>0.0</td></tr><tr><th>2</th><td>2019-12-01T00:26:05</td><td>1</td><td>0.67</td></tr><tr><th>3</th><td>2019-12-01T00:56:36</td><td>1</td><td>0.61</td></tr><tr><th>4</th><td>2019-12-01T00:26:20</td><td>1</td><td>3.9</td></tr><tr><th>5</th><td>2019-12-01T00:56:36</td><td>1</td><td>0.5</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& lpep\\_pickup\\_datetime & passenger\\_count & trip\\_distance\\\\\n",
       "\t\\hline\n",
       "\t& DateTime & Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-12-01T00:09:45 & 1 & 0.0 \\\\\n",
       "\t2 & 2019-12-01T00:26:05 & 1 & 0.67 \\\\\n",
       "\t3 & 2019-12-01T00:56:36 & 1 & 0.61 \\\\\n",
       "\t4 & 2019-12-01T00:26:20 & 1 & 3.9 \\\\\n",
       "\t5 & 2019-12-01T00:56:36 & 1 & 0.5 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ lpep_pickup_datetime │ passenger_count │ trip_distance │\n",
       "│     │ \u001b[90mDateTime\u001b[39m             │ \u001b[90mInt64\u001b[39m           │ \u001b[90mFloat64\u001b[39m       │\n",
       "├─────┼──────────────────────┼─────────────────┼───────────────┤\n",
       "│ 1   │ 2019-12-01T00:09:45  │ 1               │ 0.0           │\n",
       "│ 2   │ 2019-12-01T00:26:05  │ 1               │ 0.67          │\n",
       "│ 3   │ 2019-12-01T00:56:36  │ 1               │ 0.61          │\n",
       "│ 4   │ 2019-12-01T00:26:20  │ 1               │ 3.9           │\n",
       "│ 5   │ 2019-12-01T00:56:36  │ 1               │ 0.5           │"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(df_sample, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydf_sample = py\"$pydf[['lpep_pickup_datetime', 'passenger_count', 'trip_distance']]\";\n",
    "#pydf_sample = py\"$pydf_sample[~$pydf_sample.passenger_count.isna()]\"\n",
    "pydf_sample.passenger_count = pydf_sample.passenger_count.fillna(0)\n",
    "pydf_sample.passenger_count = np.int64(pydf_sample.passenger_count);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostgreSQL result"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute(con, \"drop table if exists test_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"create table test_taxi (\\n    lpep_pickup_datetime timestamp, \\n    passenger_count int, \\n    trip_distance numeric\\n);\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "create table test_taxi (\n",
    "    lpep_pickup_datetime timestamp, \n",
    "    passenger_count int, \n",
    "    trip_distance numeric\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostgreSQL result"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute(con, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80.469195 seconds (33.83 M allocations: 1.904 GiB, 1.15% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PostgreSQL result"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time begin\n",
    "    execute(con, \"BEGIN;\")\n",
    "    LibPQ.load!(\n",
    "        (lpep_pickup_datetime=df_sample[!, :lpep_pickup_datetime], \n",
    "        passenger_count=df_sample[!, :passenger_count], \n",
    "        trip_distance=df_sample[!, :trip_distance],),\n",
    "        con,\n",
    "        \"\"\"INSERT INTO test_taxi (lpep_pickup_datetime, passenger_count, \n",
    "            trip_distance) VALUES (\\$1, \\$2, \\$3);\"\"\")\n",
    "    execute(con, \"COMMIT;\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute(con, \"ROLLBACK;\") # in case of problems with query above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.065985 seconds (74 allocations: 4.328 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PostgreSQL result"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time execute(con, \"delete from test_taxi;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82.859435 seconds (57 allocations: 2.672 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time pydf_sample.to_sql(\"test_taxi\", pyengine, if_exists=\"append\", \n",
    "    index=false, method=\"multi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"select lpep_pickup_datetime, passenger_count, cast(trip_distance as float) from test_taxi\\n\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "select lpep_pickup_datetime, passenger_count, cast(trip_distance as float) from test_taxi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.579 s (8636246 allocations: 320.90 MiB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>lpep_pickup_datetime</th><th>passenger_count</th><th>trip_distance</th></tr><tr><th></th><th>DateTime⍰</th><th>Int32⍰</th><th>Float64⍰</th></tr></thead><tbody><p>359,902 rows × 3 columns</p><tr><th>1</th><td>2019-12-01T00:09:45</td><td>1</td><td>0.0</td></tr><tr><th>2</th><td>2019-12-01T00:26:05</td><td>1</td><td>0.67</td></tr><tr><th>3</th><td>2019-12-01T00:56:36</td><td>1</td><td>0.61</td></tr><tr><th>4</th><td>2019-12-01T00:26:20</td><td>1</td><td>3.9</td></tr><tr><th>5</th><td>2019-12-01T00:56:36</td><td>1</td><td>0.5</td></tr><tr><th>6</th><td>2019-12-01T00:14:28</td><td>1</td><td>1.1</td></tr><tr><th>7</th><td>2019-12-01T00:45:54</td><td>1</td><td>1.5</td></tr><tr><th>8</th><td>2019-12-01T00:25:35</td><td>1</td><td>7.42</td></tr><tr><th>9</th><td>2019-12-01T00:43:12</td><td>1</td><td>5.3</td></tr><tr><th>10</th><td>2019-12-01T00:56:08</td><td>1</td><td>2.64</td></tr><tr><th>11</th><td>2019-12-01T00:10:32</td><td>5</td><td>3.85</td></tr><tr><th>12</th><td>2019-12-01T00:16:41</td><td>1</td><td>0.68</td></tr><tr><th>13</th><td>2019-12-01T00:04:57</td><td>1</td><td>0.04</td></tr><tr><th>14</th><td>2019-12-01T00:32:08</td><td>1</td><td>2.97</td></tr><tr><th>15</th><td>2019-12-01T00:13:31</td><td>1</td><td>1.6</td></tr><tr><th>16</th><td>2019-12-01T00:09:15</td><td>1</td><td>0.63</td></tr><tr><th>17</th><td>2019-12-01T00:12:29</td><td>1</td><td>3.66</td></tr><tr><th>18</th><td>2019-12-01T00:30:08</td><td>1</td><td>0.5</td></tr><tr><th>19</th><td>2019-12-01T00:43:11</td><td>1</td><td>1.6</td></tr><tr><th>20</th><td>2019-12-01T00:55:42</td><td>1</td><td>0.3</td></tr><tr><th>21</th><td>2019-12-01T00:32:18</td><td>1</td><td>0.0</td></tr><tr><th>22</th><td>2019-12-01T00:47:58</td><td>1</td><td>2.44</td></tr><tr><th>23</th><td>2019-12-01T00:18:47</td><td>1</td><td>2.82</td></tr><tr><th>24</th><td>2019-12-01T00:26:26</td><td>1</td><td>3.5</td></tr><tr><th>25</th><td>2019-12-01T00:58:22</td><td>1</td><td>1.32</td></tr><tr><th>26</th><td>2019-12-01T00:10:36</td><td>1</td><td>1.09</td></tr><tr><th>27</th><td>2019-12-01T00:37:31</td><td>1</td><td>4.03</td></tr><tr><th>28</th><td>2019-12-01T00:18:19</td><td>1</td><td>3.14</td></tr><tr><th>29</th><td>2019-12-01T00:18:57</td><td>1</td><td>0.0</td></tr><tr><th>30</th><td>2019-12-01T00:23:02</td><td>1</td><td>1.84</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& lpep\\_pickup\\_datetime & passenger\\_count & trip\\_distance\\\\\n",
       "\t\\hline\n",
       "\t& DateTime⍰ & Int32⍰ & Float64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-12-01T00:09:45 & 1 & 0.0 \\\\\n",
       "\t2 & 2019-12-01T00:26:05 & 1 & 0.67 \\\\\n",
       "\t3 & 2019-12-01T00:56:36 & 1 & 0.61 \\\\\n",
       "\t4 & 2019-12-01T00:26:20 & 1 & 3.9 \\\\\n",
       "\t5 & 2019-12-01T00:56:36 & 1 & 0.5 \\\\\n",
       "\t6 & 2019-12-01T00:14:28 & 1 & 1.1 \\\\\n",
       "\t7 & 2019-12-01T00:45:54 & 1 & 1.5 \\\\\n",
       "\t8 & 2019-12-01T00:25:35 & 1 & 7.42 \\\\\n",
       "\t9 & 2019-12-01T00:43:12 & 1 & 5.3 \\\\\n",
       "\t10 & 2019-12-01T00:56:08 & 1 & 2.64 \\\\\n",
       "\t11 & 2019-12-01T00:10:32 & 5 & 3.85 \\\\\n",
       "\t12 & 2019-12-01T00:16:41 & 1 & 0.68 \\\\\n",
       "\t13 & 2019-12-01T00:04:57 & 1 & 0.04 \\\\\n",
       "\t14 & 2019-12-01T00:32:08 & 1 & 2.97 \\\\\n",
       "\t15 & 2019-12-01T00:13:31 & 1 & 1.6 \\\\\n",
       "\t16 & 2019-12-01T00:09:15 & 1 & 0.63 \\\\\n",
       "\t17 & 2019-12-01T00:12:29 & 1 & 3.66 \\\\\n",
       "\t18 & 2019-12-01T00:30:08 & 1 & 0.5 \\\\\n",
       "\t19 & 2019-12-01T00:43:11 & 1 & 1.6 \\\\\n",
       "\t20 & 2019-12-01T00:55:42 & 1 & 0.3 \\\\\n",
       "\t21 & 2019-12-01T00:32:18 & 1 & 0.0 \\\\\n",
       "\t22 & 2019-12-01T00:47:58 & 1 & 2.44 \\\\\n",
       "\t23 & 2019-12-01T00:18:47 & 1 & 2.82 \\\\\n",
       "\t24 & 2019-12-01T00:26:26 & 1 & 3.5 \\\\\n",
       "\t25 & 2019-12-01T00:58:22 & 1 & 1.32 \\\\\n",
       "\t26 & 2019-12-01T00:10:36 & 1 & 1.09 \\\\\n",
       "\t27 & 2019-12-01T00:37:31 & 1 & 4.03 \\\\\n",
       "\t28 & 2019-12-01T00:18:19 & 1 & 3.14 \\\\\n",
       "\t29 & 2019-12-01T00:18:57 & 1 & 0.0 \\\\\n",
       "\t30 & 2019-12-01T00:23:02 & 1 & 1.84 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "359902×3 DataFrame\n",
       "│ Row    │ lpep_pickup_datetime │ passenger_count │ trip_distance │\n",
       "│        │ \u001b[90mDateTime⍰\u001b[39m            │ \u001b[90mInt32⍰\u001b[39m          │ \u001b[90mFloat64⍰\u001b[39m      │\n",
       "├────────┼──────────────────────┼─────────────────┼───────────────┤\n",
       "│ 1      │ 2019-12-01T00:09:45  │ 1               │ 0.0           │\n",
       "│ 2      │ 2019-12-01T00:26:05  │ 1               │ 0.67          │\n",
       "│ 3      │ 2019-12-01T00:56:36  │ 1               │ 0.61          │\n",
       "│ 4      │ 2019-12-01T00:26:20  │ 1               │ 3.9           │\n",
       "│ 5      │ 2019-12-01T00:56:36  │ 1               │ 0.5           │\n",
       "│ 6      │ 2019-12-01T00:14:28  │ 1               │ 1.1           │\n",
       "│ 7      │ 2019-12-01T00:45:54  │ 1               │ 1.5           │\n",
       "│ 8      │ 2019-12-01T00:25:35  │ 1               │ 7.42          │\n",
       "│ 9      │ 2019-12-01T00:43:12  │ 1               │ 5.3           │\n",
       "│ 10     │ 2019-12-01T00:56:08  │ 1               │ 2.64          │\n",
       "⋮\n",
       "│ 359892 │ 2019-12-31T23:03:23  │ 1               │ 1.06          │\n",
       "│ 359893 │ 2019-12-31T23:12:33  │ 1               │ 0.82          │\n",
       "│ 359894 │ 2019-12-31T23:40:39  │ 1               │ 0.93          │\n",
       "│ 359895 │ 2019-12-31T23:48:25  │ 1               │ 2.15          │\n",
       "│ 359896 │ 2019-12-31T23:00:09  │ 1               │ 0.54          │\n",
       "│ 359897 │ 2019-12-31T23:17:45  │ 1               │ 6.45          │\n",
       "│ 359898 │ 2019-12-31T23:07:37  │ 1               │ 3.77          │\n",
       "│ 359899 │ 2019-12-31T23:12:53  │ 1               │ 2.24          │\n",
       "│ 359900 │ 2019-12-31T23:56:05  │ 1               │ 4.19          │\n",
       "│ 359901 │ 2019-12-31T23:21:06  │ 1               │ 8.27          │\n",
       "│ 359902 │ 2019-12-31T23:27:53  │ 1               │ 8.9           │"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime df_from_db = execute(con, sql) |> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.580 s (53 allocations: 1.38 MiB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-01 00:09:45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-01 00:26:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-01 00:56:36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-01 00:26:20</td>\n",
       "      <td>1</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-01 00:56:36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359897</th>\n",
       "      <td>2019-12-31 23:07:37</td>\n",
       "      <td>1</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359898</th>\n",
       "      <td>2019-12-31 23:12:53</td>\n",
       "      <td>1</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359899</th>\n",
       "      <td>2019-12-31 23:56:05</td>\n",
       "      <td>1</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359900</th>\n",
       "      <td>2019-12-31 23:21:06</td>\n",
       "      <td>1</td>\n",
       "      <td>8.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359901</th>\n",
       "      <td>2019-12-31 23:27:53</td>\n",
       "      <td>1</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359902 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PyObject        lpep_pickup_datetime  passenger_count  trip_distance\n",
       "0       2019-12-01 00:09:45                1           0.00\n",
       "1       2019-12-01 00:26:05                1           0.67\n",
       "2       2019-12-01 00:56:36                1           0.61\n",
       "3       2019-12-01 00:26:20                1           3.90\n",
       "4       2019-12-01 00:56:36                1           0.50\n",
       "...                     ...              ...            ...\n",
       "359897  2019-12-31 23:07:37                1           3.77\n",
       "359898  2019-12-31 23:12:53                1           2.24\n",
       "359899  2019-12-31 23:56:05                1           4.19\n",
       "359900  2019-12-31 23:21:06                1           8.27\n",
       "359901  2019-12-31 23:27:53                1           8.90\n",
       "\n",
       "[359902 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime begin\n",
    "    pydf_from_db = pd.read_sql(sql, pyengine)\n",
    "    pydf_from_db.passenger_count = np.int32(pydf_from_db.passenger_count)\n",
    "    pydf_from_db\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast DB Writing using CSV Copy\n",
    "\n",
    "Inserting large amount of data using SQL is very inefficient. A much faster way is to upload the data in csv format to the database, and let the database import it to the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Julia implementation is inspired by https://invenia.github.io/LibPQ.jl/stable/#COPY-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "using IterTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insert_by_copy!"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Only for illustration purposes. Does not support `,` inside columns.\n",
    "\"\"\"\n",
    "function insert_by_copy!(con:: LibPQ.Connection, tablename:: AbstractString, df:: DataFrame)\n",
    "    row_strings = imap(eachrow(df)) do row\n",
    "        join((ismissing(x) ? \"\" : x for x in row), \",\")*\"\\n\"\n",
    "    end\n",
    "    copyin = LibPQ.CopyIn(\"COPY $tablename FROM STDIN (FORMAT CSV);\", row_strings)\n",
    "    execute(con, copyin)\n",
    "end      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostgreSQL result"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute(con, \"delete from test_taxi;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.357518 seconds (18.81 M allocations: 626.362 MiB, 2.87% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PostgreSQL result"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time insert_by_copy!(con, \"test_taxi\", df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>count</th></tr><tr><th></th><th>Int64⍰</th></tr></thead><tbody><p>1 rows × 1 columns</p><tr><th>1</th><td>450627</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& count\\\\\n",
       "\t\\hline\n",
       "\t& Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 450627 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1×1 DataFrame\n",
       "│ Row │ count  │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m │\n",
       "├─────┼────────┤\n",
       "│ 1   │ 450627 │"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute(con, \"select count(*) from test_taxi\") |> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas does not include this functionality directly, but gives a sample implementation in its documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function psql_insert_copy at 0x7f8d08045f80>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "def psql_insert_copy(table, conn, keys, data_iter):\n",
    "    '''\n",
    "    Alternative to_sql() *method* for DBs that support COPY FROM\n",
    "\n",
    "    source: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-sql-method\n",
    "\n",
    "    :param table:\n",
    "    :param conn:\n",
    "    :param keys:\n",
    "    :param data_iter:\n",
    "    '''\n",
    "    # gets a DBAPI connection that can provide a cursor\n",
    "    dbapi_conn = conn.connection\n",
    "    with dbapi_conn.cursor() as cur:\n",
    "        s_buf = StringIO()\n",
    "        writer = csv.writer(s_buf)\n",
    "        writer.writerows(data_iter)\n",
    "        s_buf.seek(0)\n",
    "\n",
    "        columns = ', '.join('\"{}\"'.format(k) for k in keys)\n",
    "        if table.schema:\n",
    "            table_name = '{}.{}'.format(table.schema, table.name)\n",
    "        else:\n",
    "            table_name = table.name\n",
    "\n",
    "        sql = 'COPY {} ({}) FROM STDIN WITH CSV'.format(\n",
    "            table_name, columns)\n",
    "        cur.copy_expert(sql=sql, file=s_buf)\n",
    "\"\"\"\n",
    "psql_insert_copy = py\"psql_insert_copy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostgreSQL result"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute(con, \"delete from test_taxi;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.736143 seconds (56 allocations: 2.656 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time pydf_sample.to_sql(\"test_taxi\", pyengine, if_exists=\"append\", \n",
    "    index=false, method=psql_insert_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>count</th></tr><tr><th></th><th>Int64⍰</th></tr></thead><tbody><p>1 rows × 1 columns</p><tr><th>1</th><td>450627</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& count\\\\\n",
       "\t\\hline\n",
       "\t& Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 450627 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1×1 DataFrame\n",
       "│ Row │ count  │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m │\n",
       "├─────┼────────┤\n",
       "│ 1   │ 450627 │"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute(con, \"select count(*) from test_taxi\") |> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* CSV Import: draw - Julia is significantly faster single threaded and uses multiple threads by default, but has large compile-time for the first load\n",
    "* Conversions to Datetime: draw - similar timings, but `pd.to_datetime` could automatically infer the datetime format.\n",
    "* Vectorized standard calculations (which are available in Numpy): Pandas (+) - but the more complex the calculations get, the more Julia catches up\n",
    "* Vectorized calculations using custom functions: Julia (++) - by 4 orders of magnitude in my example!\n",
    "* Iteration over rows: Julia (++) - by 2 orders of magnitude using `eachrow` (not type-stable) and 4 orders of magnitude if looping over DataFrame column Arrays. Using Numba on Numpy arrays is still a factor of 3 slower than Julia Arrays and supports only a subset of Python language.\n",
    "* Sorting: Pandas (+) - a factor of 4 faster in my example\n",
    "* Filtering: draw - no significant speed difference\n",
    "* Database read: Pandas (+) - Pandas seems to be faster for larger data sets, syntax is similar.\n",
    "* Database write: Pandas (+) - although Julia is slightly faster, no high-level syntax like Pandas `to_sql()` available yet.\n",
    "* Fast database uploads: draw - they are possible in both languages, but not built-in. Performance in Julia is slighty higher, but Pandas allows re-usage of its `to_sql()` command. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
